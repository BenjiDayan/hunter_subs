"""
This script processes video files and subtitles using Google's Gemini AI model to correct OCR-generated subtitles.
It maintains original timestamps while improving subtitle accuracy through AI-powered correction.
"""

import os
import time
import utils
# API_KEY = os.environ['GEMINI_API_KEY']
# import google.generativeai as genai
# model = genai.GenerativeModel("gemini-1.5-flash")

import subprocess
TEMP_SLICE_FN = 'temp_subtitle_slice.mp4'
TEMP_TIME_SLICE_FN = 'temp_time_slice.mp4'

def extract_subtitle_slice(fn, out_file=TEMP_SLICE_FN):
    """
    Extracts a specific portion of the video containing subtitles using ffmpeg.
    
    Args:
        fn (str): Path to the input video file
    """
    mp4_fn = fn.replace('.ts', '.mp4')
    # ffmpeg command to crop the video to the subtitle area
    # crop=530:93:380:555 specifies the dimensions and position of the subtitle area
    subprocess.run(['ffmpeg', '-y', '-i', mp4_fn, '-filter:v', 'crop=530:93:380:555', '-c:a', 'copy', out_file])

def extract_time_slice(fn, start_time, duration):
    """
    Extracts a time slice from the video using ffmpeg.
    
    Args:
        fn (str): Path to the input video file
        start_time (str): Start time in format HH:MM:SS
        duration (str): Duration in format HH:MM:SS
    """
    mp4_fn = fn.replace('.ts', '.mp4')
    # ffmpeg command to extract a time slice
    subprocess.run(['ffmpeg', '-y', '-i', mp4_fn, '-ss', start_time, '-t', duration, '-c:a', 'copy', TEMP_TIME_SLICE_FN])
    return TEMP_TIME_SLICE_FN

import re

def split_text_lines(text: str) -> list[str]:
    """
    Converts subtitle text with frame timestamps into a list of properly formatted lines.
    
    Args:
        text (str): Input text containing frame timestamps and subtitles
        
    Returns:
        list[str]: List of formatted subtitle lines with proper line breaks
    """
    if not '{' in text:
        return ''
    text = text[text.index('{'):]
    lines = text.split('\n')
    out = []
    for line in lines:
        if line == '':
            continue
        if line[0] == '{':
            out.append(line)
        else:
            out[-1] += '\\n' + line
    return out

def extract_frame_subset(contents, start_frame=3400, end_frame=41000):
    """
    Extracts a subset of frames from a subtitle file within a specified frame range.
    
    Args:
        contents (str): The subtitle file contents
        start_frame (int): Starting frame number
        end_frame (int): Ending frame number
        
    Returns:
        str: Subtitle content for the specified frame range
    """
    out = []

    s_e_sub = extract_frames(contents)
    for s, e, sub in s_e_sub:
        if start_frame <= s <= end_frame:
            out.append(f"{{{s}}}{{{e}}}{sub}")

    return ''.join(out)

def extract_frames(contents):
    """
    Converts subtitle content into a list of tuples containing frame information.
    
    Args:
        contents (str): The subtitle file contents
        
    Returns:
        list[tuple]: List of tuples containing (start_frame, end_frame, subtitle)
    """
    import re
    ptrn = re.compile(r'([{]\d*[}][{]\d*[}])(.*[\r\n][^{]*)',re.MULTILINE)
    frame_sub_pairs = re.findall(ptrn, contents)
    out = []
    for frame, sub in frame_sub_pairs:
        frame_num = int(frame[1:-1].split('}{')[0])
        frame_num_end = int(frame[1:-1].split('}{')[1])
        out.append((frame_num, frame_num_end, sub))
    return out

if __name__ == '__main__':
    # Example usage:
    # python gemini_test.py vids/LR_Chinese_001_720P[52KHD].mp4 ep1_out_26_08_2024_subset.sub ep1_out_26_08_2024_subset_gemini_simplified.sub
    # python gemini_test.py ./vids/LR_Chinese_003_720P\[52KHD\].ts ./vids/ep3_ocr.sub ./vids/ep3_gemini.sub   

    # python gemini_test.py  --time-slice="00:02:30,00:04:00" vids/LR_Chinese_001_720P\[52KHD\].ts ep1_out_07_05_2025_subset.sub ep1_out_07_05_2025_subset_gemini_simplified.sub



    # Parse command line arguments
    import argparse
    parser = argparse.ArgumentParser(description='Process video files and correct subtitles using Gemini AI')
    parser.add_argument('input_mp4_file', type=str, help='Input video file path')
    parser.add_argument('input_sub_file', type=str, help='Input subtitle file path - generated by OCR/who knows what')
    parser.add_argument('output_sub_file', type=str, help='Output subtitle file path')
    parser.add_argument('--time-slice', type=str, help='Time slice to process in format "start_time,duration" (e.g. "00:01:30,00:03:00" for 3 minutes starting at 1:30)')
    args = parser.parse_args()

    # Convert .ts to .mp4 if necessary
    fn = args.input_mp4_file
    mp4_fn = args.input_mp4_file.replace('.ts', '.mp4')
    print(mp4_fn)
    subprocess.run(['ffmpeg', '-y', '-i', fn, '-c:a', 'copy', mp4_fn])

    # Handle time slice if specified
    if args.time_slice:
        start_time, duration = args.time_slice.split(',')
        print(f"Processing time slice from {start_time} for duration {duration}")
        mp4_fn = extract_time_slice(mp4_fn, start_time, duration)

    # Upload video to Gemini for processing
    # whole_vid = genai.upload_file(mp4_fn)
    # print(whole_vid.name)

    # Extract subtitle slice and process it
    extract_subtitle_slice(mp4_fn, out_file=TEMP_SLICE_FN)
    foo = utils.VideoSubExtractor(TEMP_SLICE_FN)
    foo.get_subs(max_n=None, use_tqdm=True, out_file=args.input_sub_file, trad2simple=False)

    # Read and process subtitle file
    with open(args.input_sub_file) as file:
        my_subs = file.read()
        my_subs = extract_frame_subset(my_subs)

    # Wait for video processing to complete
    while True:
        if genai.get_file(whole_vid.name).state.value == 2:
            break
        print('waiting for video to be processed...')
        time.sleep(5)

    # Prepare prompt for Gemini AI
    prompt = """
    Please help me extract the subtitles of this video in traditional chinese.
    I already have an initial transcription using OCR, but it has some mistakes - some characters may be missing or incorrectly transcribed.
    Please correct the transcribed subtitles by matching to the audio and video; change and add characters as needed, but keep the timestamps the same.
    The characters are in traditional chinese, no need to convert them to simplified chinese.
    
    I.e. given input:
    {start_frame1}{end_frame1}{subtitle1}
    {start_frame2}{end_frame2}{subtitle2}
    ...

    Please output:
    {start_frame1}{end_frame1}{corrected_subtitle1}
    {start_frame2}{end_frame2}{corrected_subtitle2}
    ...

    **Initial OCR transcription**:
    """ + my_subs

    # Generate corrected subtitles using Gemini AI
    result_final = model.generate_content(
        [whole_vid, "\n\n", prompt]
    )
    print(f"{result_final.text=}")

    # Convert traditional Chinese to simplified Chinese
    import opencc
    cc = opencc.OpenCC('t2s')
    out_simplified = cc.convert(result_final.text)
    
    # Merge and align corrected subtitles with original timestamps
    a = extract_frames('\n'.join(split_text_lines(out_simplified)))
    b = extract_frames('\n'.join(split_text_lines(my_subs)))
    c = []
    i, j = (0, 0)
    while i < len(a) and j < len(b):
        s1, e1, sub1 = a[i]
        s2, e2, sub2 = b[j]
        if s1 == s2 and e1 == e2:
            c.append((s1, e1, sub1))
            i += 1
            j += 1
        else:
            # Handle frame alignment edge cases
            if len(c) > 0 and s1 < c[-1][0]:
                i += 1
            elif s1 < s2:
                i += 1
                c.append((s1, e1, sub1))
            elif s1 > s2:
                j += 1
            else:  # s1 == s2 but e1 != e2
                i += 1
                j += 1
                c.append((s1, e1, sub1))
    out = ''.join([f'{{{s}}}{{{e}}}{sub}' for s, e, sub in c])

    # Write final corrected subtitles to output file
    with open(args.output_sub_file, 'w') as file:
        file.write(out)